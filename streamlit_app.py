import streamlit as st
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
import torch

# --- USTAWIENIA APLIKACJI ---
st.set_page_config(page_title="EN â†’ DE Translator", page_icon="ğŸŒ")
st.balloons()
st.title("ğŸŒ English â†’ German Translator")
st.markdown("""
Aplikacja tÅ‚umaczÄ…ca tekst z **angielskiego na niemiecki**  
przy uÅ¼yciu modelu **Helsinki-NLP/opus-mt-en-de**.
""")

st.image("https://www.publicdomainpictures.net/pictures/250000/velka/german-flag.jpg", width=200)
st.image("https://wallpaperaccess.com/full/96007.jpg", width=200)
st.divider()

# --- KESZOWANIE MODELI ---
@st.cache_resource(show_spinner=False)
def load_translation_model():
    tokenizer = AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-en-de", use_fast=False)
    model = AutoModelForSeq2SeqLM.from_pretrained("Helsinki-NLP/opus-mt-en-de")
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token or tokenizer.sep_token
    model.config.pad_token_id = tokenizer.pad_token_id
    return tokenizer, model

@st.cache_resource(show_spinner=False)
def load_sentiment_pipeline():
    return pipeline("sentiment-analysis")

# --- WYBÃ“R FUNKCJI ---
option = st.selectbox(
    "Opcje",
    [
        "WydÅºwiÄ™k emocjonalny tekstu (eng)",
        "TÅ‚umacz EN â†’ DE",
    ],
)

st.divider()

# --- OPCJA: ANALIZA WYDÅ¹WIÄ˜KU ---
if option == "WydÅºwiÄ™k emocjonalny tekstu (eng)":
    text = st.text_area(label="âœï¸ Wpisz tekst po angielsku do analizy:", height=150, key="sent_text")
    
    if st.button("ğŸ§  Analizuj wydÅºwiÄ™k"):
        if not text.strip():
            st.error("âš ï¸ ProszÄ™ wpisaÄ‡ tekst do analizy!")
        else:
            try:
                classifier = load_sentiment_pipeline()
                answer = classifier(text)
                st.success("âœ… Analiza zakoÅ„czona!")
                st.write(answer)  # <-- tu uproszczone wyÅ›wietlanie
            except Exception as e:
                st.error(f"âŒ BÅ‚Ä…d podczas analizy: {e}")

# --- OPCJA: TÅUMACZ EN â†’ DE ---
elif option == "TÅ‚umacz EN â†’ DE":
    text = st.text_area("âœï¸ Wpisz tekst po angielsku:", height=150, key="trans_text")
    
    if st.button("ğŸ” TÅ‚umacz"):
        if not text.strip():
            st.error("âš ï¸ ProszÄ™ wpisaÄ‡ tekst do tÅ‚umaczenia!")
        else:
            try:
                tokenizer, model = load_translation_model()
                enc = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
                with torch.no_grad():
                    out = model.generate(
                        **enc,
                        max_length=256,
                        num_beams=5,
                        early_stopping=True
                    )
                translation = tokenizer.decode(out[0], skip_special_tokens=True)
                st.success("âœ… TÅ‚umaczenie zakoÅ„czone!")
                st.subheader("ğŸ“˜ Wynik tÅ‚umaczenia:")
                st.write(translation)
            except Exception as e:
                st.error(f"âŒ BÅ‚Ä…d podczas tÅ‚umaczenia: {e}")

st.divider()
st.caption("ğŸ‘¨â€ğŸ“ Autor: Student nr indeksu **28539**")
